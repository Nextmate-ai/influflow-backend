# -*- coding: utf-8 -*-
"""
Model Comparison Test

æ¯”è¾ƒ GPT-4.1 vs GPT-4o åœ¨ bullet point æ ¼å¼éµå®ˆæ–¹é¢çš„è¡¨ç°
"""

import asyncio
import re
import sys
import os

# å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from influflow.graph.generate_tweet import graph


async def test_model_formatting(model_name: str, topic: str):
    """æµ‹è¯•ç‰¹å®šæ¨¡å‹çš„æ ¼å¼éµå®ˆèƒ½åŠ›"""
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"ğŸ“ ä¸»é¢˜: {topic}")
    print("-" * 50)
    
    config = {
        "configurable": {
            "writer_provider": "openai",
            "writer_model": model_name,
            "writer_model_kwargs": {}
        }
    }
    
    input_state = {
        "topic": topic,
        "language": "English"
    }
    
    try:
        result = await graph.ainvoke(input_state, config)
        thread_text = result.get("tweet_thread", "")
        
        # è§£ææ¨æ–‡
        tweets = re.findall(r'\((\d+)/\d+\)(.*?)(?=\n\(\d+/\d+\)|$)', thread_text, re.DOTALL)
        
        bullet_stats = {
            "total_tweets": len(tweets),
            "tweets_with_bullets": 0,
            "correct_bullet_format": 0,
            "incorrect_examples": []
        }
        
        for tweet_num, content in tweets:
            content = content.strip()
            
            if 'â€¢' in content:
                bullet_stats["tweets_with_bullets"] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åŒè¡Œçš„ bullets
                same_line_bullets = re.search(r'â€¢[^â€¢\n]*â€¢', content)
                
                if same_line_bullets:
                    bullet_stats["incorrect_examples"].append({
                        "tweet_num": tweet_num,
                        "problem": "åŒè¡Œå¤šä¸ªbullets",
                        "content": content[:100] + "..."
                    })
                else:
                    bullet_stats["correct_bullet_format"] += 1
        
        # æ‰“å°ç»“æœ
        print(f"âœ… ç”Ÿæˆå®Œæˆ")
        print(f"ğŸ“Š æ€»æ¨æ–‡: {bullet_stats['total_tweets']}")
        print(f"ğŸ“ åŒ…å«bullets: {bullet_stats['tweets_with_bullets']}")
        
        if bullet_stats["tweets_with_bullets"] > 0:
            success_rate = bullet_stats["correct_bullet_format"] / bullet_stats["tweets_with_bullets"] * 100
            print(f"âœ… Bulletæ ¼å¼æ­£ç¡®: {bullet_stats['correct_bullet_format']}/{bullet_stats['tweets_with_bullets']} ({success_rate:.1f}%)")
            
            if bullet_stats["incorrect_examples"]:
                print(f"âŒ æ ¼å¼é”™è¯¯ç¤ºä¾‹:")
                for example in bullet_stats["incorrect_examples"][:2]:
                    print(f"   Tweet {example['tweet_num']}: {example['content']}")
        
        return bullet_stats
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return None


async def run_comparison():
    """è¿è¡Œæ¨¡å‹å¯¹æ¯”æµ‹è¯•"""
    print("ğŸš€ GPT-4.1 vs GPT-4o Bullet Point æ ¼å¼å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    topic = "Digital marketing strategies for small businesses"
    
    models = [
        "gpt-4o-mini",  # ä½œä¸ºå¯¹ç…§ç»„
        "gpt-4o", 
        "gpt-4-1106-preview"  # GPT-4.1
    ]
    
    results = {}
    
    for model in models:
        result = await test_model_formatting(model, topic)
        results[model] = result
        await asyncio.sleep(2)  # é¿å…APIé™åˆ¶
    
    # å¯¹æ¯”åˆ†æ
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å¯¹æ¯”åˆ†æç»“æœ")
    print("=" * 60)
    
    for model, stats in results.items():
        if stats:
            tweets_with_bullets = stats["tweets_with_bullets"]
            if tweets_with_bullets > 0:
                success_rate = stats["correct_bullet_format"] / tweets_with_bullets * 100
                print(f"\n{model}:")
                print(f"  Bulletæ ¼å¼æ­£ç¡®ç‡: {success_rate:.1f}%")
                print(f"  é”™è¯¯æ•°é‡: {len(stats['incorrect_examples'])}")
            else:
                print(f"\n{model}: æ²¡æœ‰ç”ŸæˆåŒ…å«bulletsçš„æ¨æ–‡")
    
    # æ˜¾ç¤ºä¸€ä¸ªå®Œæ•´ç¤ºä¾‹
    if results.get("gpt-4-1106-preview"):
        print(f"\n" + "=" * 60)
        print("ğŸ“± GPT-4.1 å®Œæ•´è¾“å‡ºç¤ºä¾‹:")
        print("=" * 60)
        
        config = {
            "configurable": {
                "writer_provider": "openai", 
                "writer_model": "gpt-4-1106-preview",
                "writer_model_kwargs": {}
            }
        }
        
        input_state = {
            "topic": topic,
            "language": "English"
        }
        
        try:
            result = await graph.ainvoke(input_state, config)
            thread_text = result.get("tweet_thread", "")
            print(thread_text)
        except Exception as e:
            print(f"æ— æ³•è·å–å®Œæ•´ç¤ºä¾‹: {str(e)}")


if __name__ == "__main__":
    asyncio.run(run_comparison()) 