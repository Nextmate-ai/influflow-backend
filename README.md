# Open Deep Research

Open Deep Research is an experimental, fully open-source research assistant that automates deep research and produces comprehensive reports on any topic. It uses a [LangGraph](https://langchain-ai.github.io/langgraph/) workflow to structure the research process. You can customize the entire research and writing process with specific models, prompts, report structure, and search tools.

### ğŸš€ Workflow

![open-deep-research-overview](https://github.com/user-attachments/assets/a171660d-b735-4587-ab2f-cd771f773756)

### ğŸƒ Quickstart

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/langchain-ai/open_deep_research.git
    cd open_deep_research
    ```

2.  **Set up your environment:**

    Copy the example environment file and edit it to add your API keys for language models and search tools.
    ```bash
    cp .env.example .env
    ```

3.  **Install dependencies and run the application:**

    The application includes a Streamlit-based user interface.

    *   **Using `uv` (recommended for Mac/Linux):**
        ```bash
        # Install uv
        curl -LsSf https://astral.sh/uv/install.sh | sh

        # Create a virtual environment and install dependencies
        uv venv
        source .venv/bin/activate
        uv pip install -e ".[dev]"
        ```

    *   **Using `pip` (for Windows/Linux):**
        ```bash
        # Create and activate a virtual environment
        python -m venv .venv
        source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`

        # Install dependencies
        pip install -e ".[dev]"
        ```

4.  **Launch the UI:**
    ```bash
    python start.py
    ```
    This will open the user interface in your browser.

5.  **è¿è¡Œ LangGraph å¹³å°ï¼ˆå¯é€‰ï¼‰:**

    é™¤äº† Streamlit UIï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ LangGraph å¹³å°è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ï¼š

    ```bash
    # å®‰è£… uv åŒ…ç®¡ç†å™¨ï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰
    curl -LsSf https://astral.sh/uv/install.sh | sh

    # å®‰è£…ä¾èµ–å¹¶å¯åŠ¨ LangGraph å¼€å‘æœåŠ¡å™¨
    BG_JOB_ISOLATED_LOOPS=true uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
    ```
    
    è¿™å°†å¯åŠ¨ LangGraph å¼€å‘æœåŠ¡å™¨ï¼Œæä¾›å›¾å½¢åŒ–ç•Œé¢æ¥è°ƒè¯•å’Œæµ‹è¯•å·¥ä½œæµã€‚

---

### ğŸš¢ éƒ¨ç½² Deployment

#### 1. Docker æœ¬åœ°/æœåŠ¡å™¨éƒ¨ç½²

ä»“åº“å·²æä¾› `Dockerfile`ï¼Œå¯ä¸€é”®æ„å»ºé•œåƒå¹¶è¿è¡Œï¼š
```bash
# æ„å»ºé•œåƒï¼ˆå¦‚éœ€è‡ªå®šä¹‰TAGå¯è‡ªè¡Œä¿®æ”¹ï¼‰
docker build -t open-deep-research:latest .

# è¿è¡Œå®¹å™¨ï¼Œæ˜ å°„é»˜è®¤çš„ 8501 ç«¯å£
# è¯·ç”¨ -e ä¼ é€’æ¨¡å‹ / æœç´¢ API KEYï¼Œæˆ–æŒ‚è½½è‡ªå®šä¹‰ .env æ–‡ä»¶

docker run -it --rm -p 8501:8501 \
  -e OPENAI_API_KEY=your_key \
  -e TAVILY_API_KEY=your_key \
  open-deep-research:latest
```
å¯åŠ¨åè®¿é—® `http://localhost:8501` å³å¯ã€‚

#### 2. Railway äº‘éƒ¨ç½²

å·²æä¾› `railway.json` é…ç½®ä¸è¾…åŠ©è„šæœ¬ `deploy.sh`ï¼š
```bash
# å®‰è£…ä¾èµ–ï¼ˆéœ€å…ˆå®‰è£… Node & npmï¼‰
npm install -g @railway/cli

# ä¸€é”®åˆ›å»ºå¹¶éƒ¨ç½²ï¼ˆä¼šæç¤ºè¾“å…¥ API KEYï¼‰
./deploy.sh
```
è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. æ£€æŸ¥/å®‰è£… Railway CLI å¹¶ç™»å½•ã€‚
2. åˆ›å»ºåä¸º `open-deep-research` çš„é¡¹ç›®ã€‚
3. æ ¹æ®æç¤ºå†™å…¥ç¯å¢ƒå˜é‡ã€‚
4. ä½¿ç”¨ `Dockerfile` æ„å»ºå¹¶éƒ¨ç½²ã€‚

éƒ¨ç½²å®Œæˆåï¼Œå¯åœ¨ Railway Dashboard æŸ¥çœ‹ URL ä¸æ—¥å¿—ã€‚

#### 3. å…¶ä»–å¹³å°
- **Streamlit Community Cloud / Hugging Face Spaces**ï¼šå…¥å£æ–‡ä»¶å‡ä¸º `start.py`ï¼›å°† `.env` ä¸­çš„å˜é‡å¡«å…¥å„å¹³å°çš„ Secrets å³å¯ã€‚
- **Vercel / Netlify**ï¼šå»ºè®®å…ˆç”¨ Docker å®¹å™¨æˆ– Cloud Run éƒ¨ç½²åå†åšåå‘ä»£ç†ã€‚

> âš ï¸ è¯·å‹¿å°†åŒ…å«æ•æ„Ÿä¿¡æ¯çš„ `.env` æ–‡ä»¶æäº¤åˆ°å…¬å…±ä»“åº“ï¼ŒåŠ¡å¿…é€šè¿‡å¹³å° Secrets æˆ–å‘½ä»¤è¡Œ `-e` å‚æ•°æ³¨å…¥ã€‚

### ğŸ“ How to Use

1.  **Enter a topic** for your research in the input box.
2.  The system will generate a **research plan**. You can review it.
3.  If you are satisfied with the plan, click **"Accept"** to proceed. If you want to modify it, provide your feedback in the text box and click **"Regenerate"**.
4.  Once the plan is accepted, the workflow will execute the research and generate a **comprehensive report** in Markdown format.

### ğŸ› ï¸ Search Tools

You can configure the workflow to use various search tools. Set your preferences and API keys in the `.env` file.

*   [Tavily API](https://tavily.com/)
*   [Perplexity API](https://www.perplexity.ai/)
*   [Exa API](https://exa.ai/)
*   [ArXiv](https://arxiv.org/)
*   [PubMed](https://pubmed.ncbi.nlm.nih.gov/)
*   [Linkup API](https://www.linkup.so/)
*   [DuckDuckGo API](https://duckduckgo.com/)
*   [Google Search API](https://developers.google.com/custom-search/v1/introduction)
*   [Microsoft Azure AI Search](https://azure.microsoft.com/en-us/products/ai-services/ai-search)

### âš™ï¸ Advanced Configuration

#### Customizing the Workflow

You can customize the research workflow through several parameters:

- `report_structure`: Define a custom structure for your report.
- `number_of_queries`: Number of search queries to generate per section (default: 2).
- `max_search_depth`: Maximum number of reflection and search iterations (default: 2).
- `planner_provider` / `planner_model`: The model used for planning the report.
- `writer_provider` / `writer_model`: The model used for writing the report sections.
- `search_api`: The search API to use.

#### Search API Configuration

Some search APIs support additional configuration parameters.

- **Exa**: `max_characters`, `num_results`, `include_domains`, `exclude_domains`, `subpages`
- **ArXiv**: `load_max_docs`, `get_full_documents`, `load_all_available_meta`
- **PubMed**: `top_k_results`, `email`, `api_key`, `doc_content_chars_max`
- **Linkup**: `depth`

Example with Exa configuration:
```python
thread = {"configurable": {"thread_id": str(uuid.uuid4()),
                           "search_api": "exa",
                           "search_api_config": {
                               "num_results": 5,
                               "include_domains": ["nature.com", "sciencedirect.com"]
                           },
                           # Other configuration...
                           }}
```

### ğŸ¤– Model Considerations

1.  **Model Support**: You can use models supported by [the `init_chat_model()` API](https://python.langchain.com/docs/how_to/chat_models_universal_init/).
2.  **Structured Outputs**: The workflow's planner and writer models must support structured outputs/function calling. Check your model provider's documentation. Models from OpenAI, Anthropic, and Google generally work well.
3.  **Local Models**: For guidance on using local models with Ollama, see [this issue](https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318).

### ğŸ§ª Evaluation

The project includes a `pytest`-based evaluation system to assess report quality.

- **Run evaluation:**
  ```bash
  # Test with specific models
  python tests/run_test.py --planner-model "openai:gpt-4o" --writer-model "openai:gpt-4o" --eval-model "openai:gpt-4o"
  ```
- **Key Files:**
  - `tests/run_test.py`: Main test runner.
  - `tests/test_report_quality.py`: Core test implementation.
  - `tests/conftest.py`: Pytest configuration.

### ğŸ¤ Contributing

Contributions are welcome! Please feel free to open an issue or submit a pull request.

### ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
- Gate-keeping before production deployments

**Use LangSmith System for:**
- Comprehensive model evaluation across datasets
- Research and analysis of system performance
- Detailed performance profiling and benchmarking
- Comparative studies between different configurations
- Production monitoring and quality assurance

Both evaluation systems complement each other and provide comprehensive coverage for different use cases and development stages.

## UX

### Local deployment

Follow the [quickstart](#-quickstart) to start LangGraph server locally.

### Hosted deployment
 
You can easily deploy to [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/#deployment-options). 
